{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e111e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Anaconda\\anaconda3\\envs\\space\\Lib\\site-packages\\rdflib\\plugins\\serializers\\nt.py:39: UserWarning: NTSerializer always uses UTF-8 encoding. Given encoding was: None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# SECTION 1 ‚Äî KG Initialization\n",
    "# ===========================\n",
    "\n",
    "from rdflib import Graph, Namespace, URIRef, RDF, RDFS, OWL, Literal\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "\n",
    "# -----------------------------\n",
    "# NAMESPACE\n",
    "# -----------------------------\n",
    "NELL = Namespace(\"http://nell-995.org/\")\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD YOUR GRAPH (exactly as you had it)\n",
    "# -----------------------------\n",
    "g = Graph()\n",
    "g.bind(\"nell\", NELL)\n",
    "g.bind(\"owl\", OWL)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "SPORT_RELATIONS = {\n",
    "    \"athleteplayssport\",\n",
    "    \"athleteplayssport_inv\",\n",
    "    \"athleteplaysforteam\",\n",
    "    \"athleteplaysforteam_inv\",\n",
    "    \"athleteplayssportsteamposition\",\n",
    "    \"athleteplayssportsteamposition_inv\",\n",
    "    \"athleteflyouttosportsteamposition\",\n",
    "    \"athleteflyouttosportsteamposition_inv\",\n",
    "}\n",
    "# Generic entity class\n",
    "g.add((NELL.Entity, RDF.type, OWL.Class))\n",
    "\n",
    "def clean_uri(text):\n",
    "    return text.replace(\"concept:\", \"\").replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "def is_sport_relation(rel):\n",
    "    rel = rel.lower()\n",
    "    return rel in SPORT_RELATIONS\n",
    "# Load your KB file\n",
    "path = \"kb_env_rl.txt\"\n",
    "i = 0\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 3:\n",
    "            subject, obj, relation = parts\n",
    "            s = URIRef(f\"{clean_uri(subject)}\")\n",
    "            r = URIRef(f\"{clean_uri(relation)}\")\n",
    "            o = URIRef(f\"{clean_uri(obj)}\")\n",
    "            if not is_sport_relation(r):\n",
    "                continue\n",
    "            g.add((s, r, o))\n",
    "            g.add((r, RDF.type, OWL.ObjectProperty))\n",
    "            g.add((s, RDF.type, NELL.Entity))\n",
    "            g.add((o, RDF.type, NELL.Entity))\n",
    "            i += 1\n",
    "\n",
    "g.serialize(destination=\"knowledge_graph.nt\", format=\"nt\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# HELPER FUNCTIONS\n",
    "# -----------------------------\n",
    "def clean_uri_fragment(text):\n",
    "    frag = text.replace(\"concept:\", \"\").replace(\":\", \"_\").replace(\"/\", \"_\").strip()\n",
    "    frag = re.sub(r\"\\s+\", \"_\", frag)\n",
    "    frag = re.sub(r\"[^\\w\\-_.]\", \"\", frag)\n",
    "    return frag\n",
    "\n",
    "def text_to_uri(text, ns=NELL):\n",
    "    return URIRef(f\"{ns}{clean_uri_fragment(text)}\")\n",
    "\n",
    "def get_labels(node, graph):\n",
    "    labels = set()\n",
    "\n",
    "    # rdfs:label if present\n",
    "    for L in graph.objects(node, RDFS.label):\n",
    "        if isinstance(L, Literal):\n",
    "            labels.add(str(L))\n",
    "\n",
    "    if isinstance(node, URIRef):\n",
    "        raw = str(node).split(\"/\")[-1]  # e.g., concept_city_vegas\n",
    "\n",
    "        # Original label\n",
    "        labels.add(raw.replace(\"_\", \" \"))\n",
    "\n",
    "        # Remove concept_ prefix\n",
    "        if raw.startswith(\"concept_\"):\n",
    "            labels.add(raw[len(\"concept_\"):].replace(\"_\", \" \"))\n",
    "\n",
    "        # Remove category prefix (e.g., city_, visualizablething_, etc.)\n",
    "        parts = raw.split(\"_\", 2)\n",
    "        if len(parts) >= 3:\n",
    "            labels.add(parts[2].replace(\"_\", \" \"))\n",
    "\n",
    "        # Add last fragment\n",
    "        labels.add(parts[-1])\n",
    "\n",
    "        # Add space-joined fragments after category prefix if more than 2\n",
    "        if len(parts) > 2:\n",
    "            labels.add(\" \".join(parts[1:]))\n",
    "            labels.add(\" \".join(parts[2:]))\n",
    "\n",
    "    return labels\n",
    "\n",
    "# -----------------------------\n",
    "# EXACT TRIPLE CHECK\n",
    "# -----------------------------\n",
    "def exists_exact_triple(graph, subj_text, rel_text, obj_text):\n",
    "    s = text_to_uri(subj_text)\n",
    "    r = text_to_uri(rel_text)\n",
    "    o = text_to_uri(obj_text)\n",
    "    return (s, r, o) in graph\n",
    "\n",
    "# -----------------------------\n",
    "# FUZZY LABEL MATCH\n",
    "# -----------------------------\n",
    "def find_by_label(graph, text, threshold=60):  \n",
    "    candidates = set(graph.subjects()) | set(graph.objects())\n",
    "\n",
    "    results = []\n",
    "    for node in candidates:\n",
    "        labels = get_labels(node, graph)\n",
    "        if not labels:\n",
    "            continue\n",
    "        best = max(fuzz.ratio(text.lower(), lab.lower()) for lab in labels)\n",
    "        if best >= threshold:\n",
    "            results.append((node, best))\n",
    "\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# SIMILAR TRIPLE SEARCH\n",
    "# -----------------------------\n",
    "def find_similar_triples(graph, subj, rel, obj, label_threshold=85, rel_threshold=20):\n",
    "    matches = {\n",
    "        \"exact\": exists_exact_triple(graph, subj, rel, obj),\n",
    "        \"matched_subjects\": [],\n",
    "        \"matched_objects\": [],\n",
    "        \"candidate_predicates\": [],\n",
    "        \"similar_triples\": []\n",
    "    }\n",
    "\n",
    "    if matches[\"exact\"]:\n",
    "        return matches\n",
    "\n",
    "    # subject & object fuzzy matches\n",
    "    matches[\"matched_subjects\"] = find_by_label(graph, subj, threshold=label_threshold)\n",
    "    matches[\"matched_objects\"] = find_by_label(graph, obj, threshold=label_threshold)\n",
    "\n",
    "    # predicate fuzzy match\n",
    "    rel_norm = rel.replace(\"_\", \" \").strip()\n",
    "    for r in set(graph.predicates()):\n",
    "        frag = str(r).split(\"/\")[-1].replace(\"_\", \" \")\n",
    "        score = fuzz.ratio(rel_norm, frag)\n",
    "        if score >= rel_threshold:\n",
    "            matches[\"candidate_predicates\"].append((r, score))\n",
    "\n",
    "    # possible similar triples\n",
    "    for s_node, s_score in matches[\"matched_subjects\"]:\n",
    "        for o_node, o_score in matches[\"matched_objects\"]:\n",
    "            for r in graph.predicates(subject=s_node, object=o_node):\n",
    "                frag = str(r).split(\"/\")[-1].replace(\"_\", \" \")\n",
    "                rel_score = fuzz.ratio(rel, frag)\n",
    "\n",
    "                matches[\"similar_triples\"].append({\n",
    "                    \"s\": s_node,\n",
    "                    \"r\": r,\n",
    "                    \"o\": o_node,\n",
    "                    \"scores\": {\n",
    "                        \"subject\": s_score,\n",
    "                        \"predicate\": rel_score,\n",
    "                        \"object\": o_score\n",
    "                    }\n",
    "                })\n",
    "\n",
    "    # sort by relevance\n",
    "    matches[\"similar_triples\"].sort(\n",
    "        key=lambda t: sum(t[\"scores\"].values()), \n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    return matches\n",
    "\n",
    "# -----------------------------\n",
    "# FINAL FUNCTION TO CALL FROM SECTION 2\n",
    "# -----------------------------\n",
    "def check_rebel_triple_against_nell(graph, triple):\n",
    "    \"\"\"\n",
    "    triple = { \"subject\": \"...\", \"relation\": \"...\", \"object\": \"...\" }\n",
    "    \"\"\"\n",
    "    subj = triple[\"subject\"]\n",
    "    rel  = triple[\"relation\"]\n",
    "    obj  = triple[\"object\"]\n",
    "\n",
    "    result = find_similar_triples(graph, subj, rel, obj)\n",
    "\n",
    "    return {\n",
    "        \"input_triple\": triple,\n",
    "        \"exists_exact\": result[\"exact\"],\n",
    "        \"matched_subjects\": result[\"matched_subjects\"],\n",
    "        \"matched_objects\": result[\"matched_objects\"],\n",
    "        \"candidate_predicates\": result[\"candidate_predicates\"],\n",
    "        \"similar_triples\": result[\"similar_triples\"]\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# CHECK IF NAME / ENTITY EXISTS IN NELL\n",
    "# -----------------------------\n",
    "def entity_exists_exact(graph, name):\n",
    "    \"\"\"\n",
    "    Check if an entity URI matching the cleaned name exists in the graph.\n",
    "    \"\"\"\n",
    "    uri = text_to_uri(name)\n",
    "    return (uri, None, None) in graph or (None, None, uri) in graph\n",
    "\n",
    "\n",
    "def entity_exists_fuzzy(graph, name, threshold=70):\n",
    "    \"\"\"\n",
    "    Find entities with labels similar to 'name'.\n",
    "    \"\"\"\n",
    "    return find_by_label(graph, name, threshold=threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "786f6b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "     NELL FACT-CHECKING CHATBOT     \n",
      "==============================================\n",
      " Escreve qualquer frase para analisar.\n",
      " Escreve 'exit' para sair.\n",
      "----------------------------------------------\n",
      "\n",
      "A analisar...\n",
      "\n",
      "\n",
      "üìå Rela√ß√µes Extra√≠das pelo REBEL: [{'subject': 'Elton Brand', 'relation': 'sport', 'object': 'basketball', 'subject_id': None, 'object_id': None}, {'subject': 'Ronaldo', 'relation': 'sport', 'object': 'basketball', 'subject_id': None, 'object_id': None}]\n",
      "\n",
      "Verifica√ß√£o das rela√ß√µes com NELL:\n",
      "\n",
      "REBEL: [Elton Brand] --(sport)--> [basketball]\n",
      "~ Sujeito aproximado: concept_athlete_elton_brand (score=100.0)\n",
      "~ Objeto aproximado: concept_sport_basketball (score=100.0)\n",
      "~ Triplo semelhante encontrado em NELL:\n",
      "    concept_athlete_elton_brand --athleteplayssport--> concept_sport_basketball (scores={'subject': 100.0, 'predicate': 45.45454545454546, 'object': 100.0})\n",
      "\n",
      "REBEL: [Ronaldo] --(sport)--> [basketball]\n",
      "~ Sujeito aproximado: concept_athlete_ronaldo (score=100.0)\n",
      "~ Objeto aproximado: concept_sport_basketball (score=100.0)\n",
      "‚úó Triplo n√£o existe em NELL\n",
      "  Tentando verificar rela√ß√£o funcional...\n",
      "  Nenhuma rela√ß√£o candidata encontrada.\n",
      "Groq\n",
      "A sair... üëã\n"
     ]
    }
   ],
   "source": [
    "from groq import Groq\n",
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "client = Groq(\n",
    "\n",
    "    api_key=\"key\",\n",
    "\n",
    ")\n",
    "\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "def embedding_relation_similarity(rebel_rel, graph):\n",
    "    \"\"\"\n",
    "    Compare a REBEL relation to all KG relations using embedding cosine similarity.\n",
    "    No normalization. \n",
    "    \"\"\"\n",
    "    rebel_emb = embedder.encode(rebel_rel, convert_to_tensor=True)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for r in set(graph.predicates()):\n",
    "        kg_label = str(r).split(\"/\")[-1].replace(\"_\", \" \").lower()\n",
    "        kg_emb = embedder.encode(kg_label, convert_to_tensor=True)\n",
    "\n",
    "        cos = util.cos_sim(rebel_emb, kg_emb).item()\n",
    "        results.append({\n",
    "            \"kg_relation\": kg_label,\n",
    "            \"embedding_score\": cos\n",
    "        })\n",
    "\n",
    "    # order from most similar to least\n",
    "    results.sort(key=lambda x: x[\"embedding_score\"], reverse=True)\n",
    "    return results\n",
    "def relation(graph, subj_uri, obj_uri, candidate_relations):\n",
    "    \"\"\"\n",
    "    Verifica quais das rela√ß√µes candidatas realmente existem\n",
    "    entre os dois n√≥s no KG.\n",
    "    subj_uri e obj_uri j√° s√£o URIRef do grafo.\n",
    "    \"\"\"\n",
    "\n",
    "    found = []\n",
    "    for rel_label in candidate_relations:\n",
    "        # Normalize the candidate relation label\n",
    "        rel_norm = rel_label.strip().lower().replace(\" \", \"_\")\n",
    "        \n",
    "        # Search through unique matches\n",
    "        for pred_uri in set(graph.predicates()):\n",
    "            pred_frag = str(pred_uri).split(\"/\")[-1].lower()\n",
    "            \n",
    "            # Check if this predicate matches the candidate\n",
    "            if pred_frag == rel_norm or rel_norm in pred_frag or pred_frag in rel_norm:\n",
    "                \n",
    "                #verificar se esse triplo ha no grafo\n",
    "                if (subj_uri, pred_uri, obj_uri) in graph:\n",
    "                    found.append((pred_frag, \"forward\"))\n",
    "                if (obj_uri, pred_uri, subj_uri) in graph:\n",
    "                    found.append((pred_frag, \"inverse\"))\n",
    "\n",
    "                \n",
    "    \n",
    "    return found\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load Models\n",
    "# -----------------------------------------------------------------------------\n",
    "tokenizer_rebel = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model_rebel = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Cleaning\n",
    "# -----------------------------------------------------------------------------\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9\\s,.!?-]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# RELATION NORMALIZATION & ADVANCED SIMILARITY\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def normalize_nell_relation(rel_uri):\n",
    "    \"\"\"Convert NELL predicate URI into human-readable form.\"\"\"\n",
    "    frag = str(rel_uri).split(\"/\")[-1]              # athleteplayssport\n",
    "    frag = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", frag) # athlete plays sport\n",
    "    frag = frag.replace(\"_\", \" \")                   # athlete plays sport\n",
    "    return frag.lower().strip()\n",
    "\n",
    "\n",
    "def relation_token_similarity(rel1, rel2):\n",
    "    \"\"\"Compute token-overlap similarity between relations.\"\"\"\n",
    "    r1 = set(rel1.lower().split())\n",
    "    r2 = set(rel2.lower().split())\n",
    "    if not r1 or not r2:\n",
    "        return 0\n",
    "    overlap = len(r1 & r2)\n",
    "    return overlap / max(len(r1), len(r2))\n",
    "\n",
    "\n",
    "def relation_similarity(rebel_rel, nell_rel_uri):\n",
    "    \"\"\"Hybrid similarity: fuzzy + token-based.\"\"\"\n",
    "    rebel_norm = rebel_rel.lower().strip()\n",
    "    nell_norm = normalize_nell_relation(nell_rel_uri)\n",
    "\n",
    "    fuzzy_score = fuzz.ratio(rebel_norm, nell_norm) / 100.0\n",
    "    token_score = relation_token_similarity(rebel_norm, nell_norm)\n",
    "\n",
    "    # Weighted combination (token overlap is more important)\n",
    "    return 0.6 * token_score + 0.4 * fuzzy_score\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Parser for REBEL output (triples in one line)\n",
    "# -----------------------------------------------------------------------------\n",
    "def parse_rebel_output(text):\n",
    "    chunks = re.split(r\"\\s{2,}\", text.strip())\n",
    "\n",
    "    triples = []\n",
    "    i = 0\n",
    "    while i + 2 < len(chunks):\n",
    "        subj = chunks[i].strip()\n",
    "        obj  = chunks[i+1].strip()\n",
    "        rel  = chunks[i+2].strip()\n",
    "\n",
    "        triples.append({\n",
    "            \"subject\": subj,\n",
    "            \"relation\": rel,\n",
    "            \"object\": obj,\n",
    "            \"subject_id\": None,\n",
    "            \"object_id\": None\n",
    "        })\n",
    "        i += 3\n",
    "\n",
    "    return triples\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# REBEL wrapper\n",
    "# -----------------------------------------------------------------------------\n",
    "def extract_rebel_relations(text):\n",
    "    inputs = tokenizer_rebel(text, return_tensors=\"pt\", truncation=True)\n",
    "    outputs = model_rebel.generate(\n",
    "        **inputs,\n",
    "        max_length=256,\n",
    "        num_beams=3,\n",
    "        length_penalty=1.0\n",
    "    )\n",
    "\n",
    "    decoded = tokenizer_rebel.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "   \n",
    "    return parse_rebel_output(decoded)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Combined pipeline\n",
    "# -----------------------------------------------------------------------------\n",
    "def getnlp(text):\n",
    "    cleaned = clean_text(text)\n",
    "\n",
    "    return {\n",
    "        \"clean_text\": cleaned.lower(),\n",
    "        \"relations\": extract_rebel_relations(cleaned)\n",
    "    }\n",
    "    \n",
    "\n",
    "\"\"\"\"Elton Brand is a basketball player and Ronaldo is also a basketball player.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def relations(relations):\n",
    "    \"\"\"\n",
    "    Processa todas as rela√ß√µes encontradas pelo REBEL\n",
    "    usando o teu pipeline de valida√ß√£o NELL.\n",
    "    \"\"\"\n",
    "    encontrado = 0\n",
    "    output_lines = []\n",
    "\n",
    "    for tr in relations:\n",
    "        subj = tr[\"subject\"]\n",
    "        rel  = tr[\"relation\"]\n",
    "        obj  = tr[\"object\"]\n",
    "\n",
    "        out = []\n",
    "        out.append(f\"\\nREBEL: [{subj}] --({rel})--> [{obj}]\")\n",
    "\n",
    "        # -----------------------\n",
    "        # SUBJECT CHECK\n",
    "        # -----------------------\n",
    "        if entity_exists_exact(g, subj):\n",
    "            out.append(f\"‚úì Sujeito existe (exato) em NELL: {subj}\")\n",
    "        else:\n",
    "            fuzzy_s = entity_exists_fuzzy(g, subj)\n",
    "            if fuzzy_s:\n",
    "                best_uri, score = fuzzy_s[0]\n",
    "                out.append(f\"~ Sujeito aproximado: {best_uri} (score={score})\")\n",
    "                subj = best_uri\n",
    "            else:\n",
    "                out.append(f\"‚úó Sujeito n√£o encontrado: {subj}\")\n",
    "\n",
    "        # -----------------------\n",
    "        # OBJECT CHECK\n",
    "        # -----------------------\n",
    "        if entity_exists_exact(g, obj):\n",
    "            out.append(f\"‚úì Objeto existe (exato) em NELL: {obj}\")\n",
    "        else:\n",
    "            fuzzy_o = entity_exists_fuzzy(g, obj)\n",
    "            if fuzzy_o:\n",
    "                best_uri, score = fuzzy_o[0]\n",
    "                out.append(f\"~ Objeto aproximado: {best_uri} (score={score})\")\n",
    "                obj = best_uri\n",
    "            else:\n",
    "                out.append(f\"‚úó Objeto n√£o encontrado: {obj}\")\n",
    "\n",
    "        # -----------------------\n",
    "        # TRIPLE CHECK\n",
    "        # -----------------------\n",
    "        check = check_rebel_triple_against_nell(g, tr)\n",
    "\n",
    "        if check[\"similar_triples\"]:\n",
    "            out.append(\"~ Triplo semelhante encontrado em NELL:\")\n",
    "            for st in check[\"similar_triples\"][:3]:\n",
    "                out.append(f\"    {st['s']} --{st['r']}--> {st['o']} (scores={st['scores']})\")\n",
    "            encontrado += 1\n",
    "        else:\n",
    "            out.append(\"‚úó Triplo n√£o existe em NELL\")\n",
    "            out.append(\"  Tentando verificar rela√ß√£o funcional...\")\n",
    "\n",
    "            embed_scores = embedding_relation_similarity(rel, g)\n",
    "            top_relations = [s['kg_relation'] for s in embed_scores[:5]]\n",
    "            found = relation(g, subj, obj, top_relations)\n",
    "\n",
    "            if found:\n",
    "                for found_rel, direction in found:\n",
    "                    out.append(f\"  ‚úì Rela√ß√£o '{found_rel}' existe ({direction})\")\n",
    "                    encontrado += 1\n",
    "                    \n",
    "            else:\n",
    "                out.append(\"  Nenhuma rela√ß√£o candidata encontrada. Vamos ver no groq:\")\n",
    "\n",
    "                # fallback ‚Üí modelo LLM\n",
    "                question = f\"A rela√ß√£o '{subj} {rel} {obj}' √© verdadeira? S√™ breve, responde em pt pt, em menos de 50 palavras.\"\n",
    "                try:\n",
    "                    chat = client.chat.completions.create(\n",
    "                        model=\"llama-3.3-70b-versatile\",\n",
    "                        messages=[{\"role\": \"user\", \"content\": question}]\n",
    "                    )\n",
    "                    out.append(\"  Groq ‚Üí \" + chat.choices[0].message.content)\n",
    "                except:\n",
    "                    out.append(\"Groq\")\n",
    "\n",
    "        output_lines.append(\"\\n\".join(out))\n",
    "\n",
    "    return \"\\n\".join(output_lines)\n",
    "\n",
    "\n",
    "print(\"==============================================\")\n",
    "print(\"     NELL FACT-CHECKING CHATBOT     \")\n",
    "print(\"==============================================\")\n",
    "print(\" Escreve qualquer frase para analisar.\")\n",
    "print(\" Escreve 'exit' para sair.\")\n",
    "print(\"----------------------------------------------\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"\\n> \")\n",
    "\n",
    "    if user_input.lower() in {\"exit\", \"quit\"}:\n",
    "        print(\"A sair...\")\n",
    "        break\n",
    "\n",
    "    print(\"\\nA analisar...\\n\")\n",
    "\n",
    "    result = getnlp(user_input)\n",
    "\n",
    "    \n",
    "    print(\"\\nüìå Rela√ß√µes Extra√≠das pelo REBEL:\", result[\"relations\"])\n",
    "\n",
    "    if not result[\"relations\"]:\n",
    "        print(\"\\nNenhuma rela√ß√£o encontrada.\")\n",
    "        continue\n",
    "\n",
    "    print(\"\\nVerifica√ß√£o das rela√ß√µes com NELL:\")\n",
    "    print(relations(result[\"relations\"]))\n",
    "    print(\"----------------------------------------------\")\n",
    "    print(\" Escreve qualquer frase para analisar.\")\n",
    "    print(\" Escreve 'exit' para sair.\")\n",
    "    print(\"----------------------------------------------\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eecd6a84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f1d6b434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "AN√ÅLISE ESTAT√çSTICA - RELA√á√ïES ESPERADAS VS ENCONTRADAS NO GRAFO NELL\n",
      "==========================================================================================\n",
      "\n",
      "üìä RESUMO GERAL:\n",
      "   Total de senten√ßas: 51\n",
      "   Rela√ß√µes esperadas: 90\n",
      "   Rela√ß√µes encontradas: 59\n",
      "   Taxa de acerto: 65.6% (59/90)\n",
      "\n",
      "üìã DETALHES POR SENTEN√áA:\n",
      "Status   Esperadas    Encontradas     Texto                                                  \n",
      "------------------------------------------------------------------------------------------\n",
      "‚úì        1            1               Kevin Youkilis plays baseball. Today he spoke to y...  \n",
      "‚úì        1            1               Cory Wade is a player baseball.                        \n",
      "‚úì        1            1               Felix Jones plays football. Reporters met him this...  \n",
      "‚úì        1            1               Ronaldo is a man utd player.                           \n",
      "‚úì        1            1               Marcus Bank is a basketball player.                    \n",
      "‚úì        1            1               Frank plays basketball. A short sports report high...  \n",
      "‚úì        1            1               Joe Kennedy plays baseball. Fans discussed his rol...  \n",
      "‚úó        1            0               Miguel Cabrera is listed as an entity in the NELL ...  \n",
      "‚úì        1            1               DeAngelo Hall played for the Oakland Raiders. A ne...  \n",
      "‚úó        1            0               John Duddy is recognized as an entity in the NELL ...  \n",
      "‚úó        2            1               A joint interview featured Howie Clark and P. J. W...  \n",
      "‚úó        2            0               Infielder Yunel Escobar and reliever Brian Tallet ...  \n",
      "‚úó        2            1               A Spurs retrospective highlighted Manu Gin√≥bili‚Äôs ...  \n",
      "‚úì        2            2               A historical comparison connected Mark Grace with ...  \n",
      "‚úó        2            0               A long-form article explored how Bud Norris and Je...  \n",
      "‚úó        2            1               A dual-career highlight paired Xavier Nady‚Äôs time ...  \n",
      "‚úì        2            2               A tribute event honored √Ångel Miranda and Matt Whi...  \n",
      "‚úó        2            1               A documentary revisited Josh Smith‚Äôs basketball hi...  \n",
      "‚úó        2            1               A feature compared Jos√© Molina‚Äôs catching mechanic...  \n",
      "‚úì        2            2               A baseball retrospective paired Don Drysdale with ...  \n",
      "‚úì        0            0               A rumor spread that a high school basketball playe...  \n",
      "‚úì        0            0               Blogs claimed an Icelandic soccer team hired a psy...  \n",
      "‚úì        0            0               A viral post alleged that a tennis star won a matc...  \n",
      "‚úì        0            0               Reports falsely claimed a rugby club adopted AI dr...  \n",
      "‚úì        0            0               An online hoax suggested Formula 1 drivers would s...  \n",
      "‚úì        0            0               A blog insisted that chess grandmasters train by r...  \n",
      "‚úì        0            0               Fake news circulated saying golfers now use magnet...  \n",
      "‚úì        0            0               A rumor claimed esports teams require fitness test...  \n",
      "‚úì        0            0               Tabloids reported a soccer goalkeeper saved 50 sho...  \n",
      "‚úì        0            0               A false report claimed a sprinter outran a cheetah...  \n",
      "‚úó        2            1               Kevin Youkilis plays baseball. Jeremy Sowers plays...  \n",
      "‚úó        2            0               Brad Radke produced a flyout to the center field p...  \n",
      "‚úó        2            1               Mark Grace plays for the Chicago Cubs. Jeff Nelson...  \n",
      "‚úó        2            1               √Ångel Miranda plays baseball. Matt White plays bas...  \n",
      "‚úì        2            2               Yunel Escobar plays baseball. Ross Ohlendorf plays...  \n",
      "‚úó        2            0               Manu Ginobili plays for the Spurs. Asante Samuel p...  \n",
      "‚úì        2            2               Esmailin Caridad plays baseball. Josh Butler plays...  \n",
      "‚úó        2            1               Scott Baker played for the Twins. Conor Jackson pl...  \n",
      "‚úó        2            1               Robert Lang plays for the Montreal Canadiens. Jos√©...  \n",
      "‚úó        2            1               Warrick Dunn played for the Falcons. DeAngelo Hall...  \n",
      "‚úó        2            1               Kelly Stinnett plays baseball. √Ångel Miranda plays...  \n",
      "‚úì        2            2               Bud Norris plays baseball. Brian Tallet plays base...  \n",
      "‚úó        2            1               Donald Brown played for UConn. Felix Jones plays f...  \n",
      "‚úì        2            2               Jeff Nelson plays baseball. Greg Maddux plays base...  \n",
      "‚úó        2            1               Mark Grace plays for the Chicago Cubs. Esmailin Ca...  \n",
      "‚úì        5            5               A massive MLB anniversary event honored Bud Norris...  \n",
      "‚úó        5            4               A dual-sport comparison highlighted Mark Grace wit...  \n",
      "‚úó        5            4               Satchel is a baseballer. Raul Mondesi plays baseba...  \n",
      "‚úó        5            4               A Latin-American MLB special featured √Ångel Mirand...  \n",
      "‚úó        5            2               A global sports montage included Josh Smith‚Äôs bask...  \n",
      "‚úó        5            4               Raul Mondesi plays baseball. Roy Corcoran plays ba...  \n",
      "\n",
      "‚úì Correspond√™ncia perfeita: 26/51 (51.0%)\n",
      "‚úó Encontrou menos: 25/51 (49.0%)\n",
      "‚ö† Encontrou mais: 0/51 (0.0%)\n",
      "\n",
      "üìà ESTAT√çSTICAS ADICIONAIS:\n",
      "   Diferen√ßa m√©dia: -0.61\n",
      "   Erro m√°ximo: ¬±3\n",
      "   Precision: 64.84%\n"
     ]
    }
   ],
   "source": [
    "# ===== AN√ÅLISE ESTAT√çSTICA DO TEXT.TXT =====\n",
    "# Comparar rela√ß√µes esperadas vs encontradas no grafo NELL\n",
    "\n",
    "import re\n",
    "\n",
    "with open(\"text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    content = f.read()\n",
    "\n",
    "lines = content.strip().split('\\n')\n",
    "\n",
    "# Estruturas para armazenar dados\n",
    "total_sentences = 0\n",
    "total_expected_relations = 0\n",
    "total_found_relations = 0\n",
    "detailed_results = []\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"AN√ÅLISE ESTAT√çSTICA - RELA√á√ïES ESPERADAS VS ENCONTRADAS NO GRAFO NELL\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "for line in lines:\n",
    "    if not line.strip():\n",
    "        continue\n",
    "    \n",
    "    # Extrair o n√∫mero esperado (ex: [1 TRUE], [2 TRUE])\n",
    "    match = re.match(r'\\[(\\d+)', line)\n",
    "    if not match:\n",
    "        continue\n",
    "    \n",
    "    expected = int(match.group(1))\n",
    "    text = line.split(']', 1)[1].strip()\n",
    "    \n",
    "    total_sentences += 1\n",
    "    total_expected_relations += expected\n",
    "    \n",
    "    # Processar com REBEL\n",
    "    result = getnlp(text)\n",
    "    extracted_relations = result[\"relations\"]\n",
    "    \n",
    "    # Contar quantas rela√ß√µes foram realmente validadas no grafo\n",
    "    found = 0\n",
    "    for tr in extracted_relations:\n",
    "        subj = tr[\"subject\"]\n",
    "        rel  = tr[\"relation\"]\n",
    "        obj  = tr[\"object\"]\n",
    "        \n",
    "        # Tentar encontrar sujeito\n",
    "        if entity_exists_exact(g, subj):\n",
    "            subj_uri = text_to_uri(subj)\n",
    "        else:\n",
    "            fuzzy_s = entity_exists_fuzzy(g, subj, threshold=70)\n",
    "            if fuzzy_s:\n",
    "                subj_uri, _ = fuzzy_s[0]\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        # Tentar encontrar objeto\n",
    "        if entity_exists_exact(g, obj):\n",
    "            obj_uri = text_to_uri(obj)\n",
    "        else:\n",
    "            fuzzy_o = entity_exists_fuzzy(g, obj, threshold=70)\n",
    "            if fuzzy_o:\n",
    "                obj_uri, _ = fuzzy_o[0]\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        # Verificar se existe rela√ß√£o entre os n√≥s\n",
    "        check = check_rebel_triple_against_nell(g, tr)\n",
    "        \n",
    "        if check[\"similar_triples\"]:\n",
    "            found += 1\n",
    "        else:\n",
    "            # Tentar com embedding\n",
    "            embed_scores = embedding_relation_similarity(rel, g)\n",
    "            top_relations = [s['kg_relation'] for s in embed_scores[:5]]\n",
    "            rel_found = relation(g, subj_uri, obj_uri, top_relations)\n",
    "            \n",
    "            if rel_found:\n",
    "                found += 1\n",
    "    \n",
    "    total_found_relations += found\n",
    "    \n",
    "    detailed_results.append({\n",
    "        \"text\": text[:50] + \"...\" if len(text) > 50 else text,\n",
    "        \"expected\": expected,\n",
    "        \"found\": found,\n",
    "        \"match\": \"‚úì\" if found == expected else \"‚úó\"\n",
    "    })\n",
    "\n",
    "# ==================== RESUMO GERAL ====================\n",
    "print(f\"\\nüìä RESUMO GERAL:\")\n",
    "print(f\"   Total de senten√ßas: {total_sentences}\")\n",
    "print(f\"   Rela√ß√µes esperadas: {total_expected_relations}\")\n",
    "print(f\"   Rela√ß√µes encontradas: {total_found_relations}\")\n",
    "\n",
    "if total_expected_relations > 0:\n",
    "    accuracy = (total_found_relations / total_expected_relations) * 100\n",
    "    print(f\"   Taxa de acerto: {accuracy:.1f}% ({total_found_relations}/{total_expected_relations})\")\n",
    "else:\n",
    "    print(f\"   Taxa de acerto: N/A\")\n",
    "\n",
    "# ==================== DETALHES POR SENTEN√áA ====================\n",
    "print(f\"\\nüìã DETALHES POR SENTEN√áA:\")\n",
    "print(f\"{'Status':<8} {'Esperadas':<12} {'Encontradas':<15} {'Texto':<55}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "for r in detailed_results:\n",
    "    print(f\"{r['match']:<8} {r['expected']:<12} {r['found']:<15} {r['text']:<55}\")\n",
    "\n",
    "# ==================== AN√ÅLISE DE CORRESPOND√äNCIA ====================\n",
    "perfect_matches = sum(1 for r in detailed_results if r['found'] == r['expected'])\n",
    "under_found = sum(1 for r in detailed_results if r['found'] < r['expected'])\n",
    "over_found = sum(1 for r in detailed_results if r['found'] > r['expected'])\n",
    "\n",
    "print(f\"\\n‚úì Correspond√™ncia perfeita: {perfect_matches}/{total_sentences} ({perfect_matches/total_sentences*100:.1f}%)\")\n",
    "print(f\"‚úó Encontrou menos: {under_found}/{total_sentences} ({under_found/total_sentences*100:.1f}%)\")\n",
    "print(f\"‚ö† Encontrou mais: {over_found}/{total_sentences} ({over_found/total_sentences*100:.1f}%)\")\n",
    "\n",
    "# ==================== ESTAT√çSTICAS ADICIONAIS ====================\n",
    "differences = [r['found'] - r['expected'] for r in detailed_results]\n",
    "avg_difference = sum(differences) / len(differences) if differences else 0\n",
    "max_error = max(abs(d) for d in differences) if differences else 0\n",
    "\n",
    "print(f\"\\nüìà ESTAT√çSTICAS ADICIONAIS:\")\n",
    "print(f\"   Diferen√ßa m√©dia: {avg_difference:.2f}\")\n",
    "print(f\"   Erro m√°ximo: ¬±{max_error}\")\n",
    "print(f\"   Precision: {total_found_relations / (total_expected_relations + 1):.2%}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
