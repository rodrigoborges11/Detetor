{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e111e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rodmb\\anaconda3\\envs\\rebel\\lib\\site-packages\\rdflib\\plugins\\serializers\\nt.py:39: UserWarning: NTSerializer always uses UTF-8 encoding. Given encoding was: None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# SECTION 1 — KG Initialization\n",
    "# ===========================\n",
    "\n",
    "from rdflib import Graph, Namespace, URIRef, RDF, RDFS, OWL, Literal\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "\n",
    "# -----------------------------\n",
    "# NAMESPACE\n",
    "# -----------------------------\n",
    "NELL = Namespace(\"http://nell-995.org/\")\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD YOUR GRAPH (exactly as you had it)\n",
    "# -----------------------------\n",
    "g = Graph()\n",
    "g.bind(\"nell\", NELL)\n",
    "g.bind(\"owl\", OWL)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "SPORT_RELATIONS = {\n",
    "    \"athleteplayssport\",\n",
    "    \"athleteplayssport_inv\",\n",
    "    \"athleteplaysforteam\",\n",
    "    \"athleteplaysforteam_inv\",\n",
    "    \"athleteplayssportsteamposition\",\n",
    "    \"athleteplayssportsteamposition_inv\",\n",
    "    \"athleteflyouttosportsteamposition\",\n",
    "    \"athleteflyouttosportsteamposition_inv\",\n",
    "}\n",
    "# Generic entity class\n",
    "g.add((NELL.Entity, RDF.type, OWL.Class))\n",
    "\n",
    "def clean_uri(text):\n",
    "    return text.replace(\"concept:\", \"\").replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "def is_sport_relation(rel):\n",
    "    rel = rel.lower()\n",
    "    return rel in SPORT_RELATIONS\n",
    "# Load your KB file\n",
    "path = \"kb_env_rl.txt\"\n",
    "i = 0\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 3:\n",
    "            subject, obj, relation = parts\n",
    "            s = URIRef(f\"{clean_uri(subject)}\")\n",
    "            r = URIRef(f\"{clean_uri(relation)}\")\n",
    "            o = URIRef(f\"{clean_uri(obj)}\")\n",
    "            if not is_sport_relation(r):\n",
    "                continue\n",
    "            g.add((s, r, o))\n",
    "            g.add((r, RDF.type, OWL.ObjectProperty))\n",
    "            g.add((s, RDF.type, NELL.Entity))\n",
    "            g.add((o, RDF.type, NELL.Entity))\n",
    "            i += 1\n",
    "\n",
    "g.serialize(destination=\"knowledge_graph.nt\", format=\"nt\")\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# HELPER FUNCTIONS\n",
    "# -----------------------------\n",
    "def clean_uri_fragment(text):\n",
    "    frag = text.replace(\"concept:\", \"\").replace(\":\", \"_\").replace(\"/\", \"_\").strip()\n",
    "    frag = re.sub(r\"\\s+\", \"_\", frag)\n",
    "    frag = re.sub(r\"[^\\w\\-_.]\", \"\", frag)\n",
    "    return frag\n",
    "\n",
    "def text_to_uri(text, ns=NELL):\n",
    "    return URIRef(f\"{ns}{clean_uri_fragment(text)}\")\n",
    "\n",
    "def get_labels(node, graph):\n",
    "    labels = set()\n",
    "\n",
    "    # rdfs:label if present\n",
    "    for L in graph.objects(node, RDFS.label):\n",
    "        if isinstance(L, Literal):\n",
    "            labels.add(str(L))\n",
    "\n",
    "    if isinstance(node, URIRef):\n",
    "        raw = str(node).split(\"/\")[-1]  # e.g., concept_city_vegas\n",
    "\n",
    "        # Original label\n",
    "        labels.add(raw.replace(\"_\", \" \"))\n",
    "\n",
    "        # Remove concept_ prefix\n",
    "        if raw.startswith(\"concept_\"):\n",
    "            labels.add(raw[len(\"concept_\"):].replace(\"_\", \" \"))\n",
    "\n",
    "        # Remove category prefix (e.g., city_, visualizablething_, etc.)\n",
    "        parts = raw.split(\"_\", 2)\n",
    "        if len(parts) >= 3:\n",
    "            labels.add(parts[2].replace(\"_\", \" \"))\n",
    "\n",
    "        # Add last fragment\n",
    "        labels.add(parts[-1])\n",
    "\n",
    "        # Add space-joined fragments after category prefix if more than 2\n",
    "        if len(parts) > 2:\n",
    "            labels.add(\" \".join(parts[1:]))\n",
    "            labels.add(\" \".join(parts[2:]))\n",
    "\n",
    "    return labels\n",
    "\n",
    "# -----------------------------\n",
    "# EXACT TRIPLE CHECK\n",
    "# -----------------------------\n",
    "def exists_exact_triple(graph, subj_text, rel_text, obj_text):\n",
    "    s = text_to_uri(subj_text)\n",
    "    r = text_to_uri(rel_text)\n",
    "    o = text_to_uri(obj_text)\n",
    "    return (s, r, o) in graph\n",
    "\n",
    "# -----------------------------\n",
    "# FUZZY LABEL MATCH\n",
    "# -----------------------------\n",
    "def find_by_label(graph, text, threshold=60):  # lower threshold from 85 → 60\n",
    "    text_norm = text.strip()\n",
    "    candidates = set(graph.subjects()) | set(graph.objects())\n",
    "\n",
    "    results = []\n",
    "    for node in candidates:\n",
    "        labels = get_labels(node, graph)\n",
    "        if not labels:\n",
    "            continue\n",
    "        best = max(fuzz.ratio(text_norm.lower(), lab.lower()) for lab in labels)\n",
    "        if best >= threshold:\n",
    "            results.append((node, best))\n",
    "\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# SIMILAR TRIPLE SEARCH\n",
    "# -----------------------------\n",
    "def find_similar_triples(graph, subj, rel, obj, label_threshold=85, rel_threshold=20):\n",
    "    matches = {\n",
    "        \"exact\": exists_exact_triple(graph, subj, rel, obj),\n",
    "        \"matched_subjects\": [],\n",
    "        \"matched_objects\": [],\n",
    "        \"candidate_predicates\": [],\n",
    "        \"similar_triples\": []\n",
    "    }\n",
    "\n",
    "    if matches[\"exact\"]:\n",
    "        return matches\n",
    "\n",
    "    # subject & object fuzzy matches\n",
    "    matches[\"matched_subjects\"] = find_by_label(graph, subj, threshold=label_threshold)\n",
    "    matches[\"matched_objects\"] = find_by_label(graph, obj, threshold=label_threshold)\n",
    "\n",
    "    # predicate fuzzy match\n",
    "    rel_norm = rel.replace(\"_\", \" \").strip()\n",
    "    for r in set(graph.predicates()):\n",
    "        frag = str(r).split(\"/\")[-1].replace(\"_\", \" \")\n",
    "        score = fuzz.ratio(rel_norm, frag)\n",
    "        if score >= rel_threshold:\n",
    "            matches[\"candidate_predicates\"].append((r, score))\n",
    "\n",
    "    # possible similar triples\n",
    "    for s_node, s_score in matches[\"matched_subjects\"]:\n",
    "        for o_node, o_score in matches[\"matched_objects\"]:\n",
    "            for r in graph.predicates(subject=s_node, object=o_node):\n",
    "                frag = str(r).split(\"/\")[-1].replace(\"_\", \" \")\n",
    "                rel_score = fuzz.ratio(rel, frag)\n",
    "\n",
    "                matches[\"similar_triples\"].append({\n",
    "                    \"s\": s_node,\n",
    "                    \"r\": r,\n",
    "                    \"o\": o_node,\n",
    "                    \"scores\": {\n",
    "                        \"subject\": s_score,\n",
    "                        \"predicate\": rel_score,\n",
    "                        \"object\": o_score\n",
    "                    }\n",
    "                })\n",
    "\n",
    "    # sort by relevance\n",
    "    matches[\"similar_triples\"].sort(\n",
    "        key=lambda t: sum(t[\"scores\"].values()), \n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    return matches\n",
    "\n",
    "# -----------------------------\n",
    "# FINAL FUNCTION TO CALL FROM SECTION 2\n",
    "# -----------------------------\n",
    "def check_rebel_triple_against_nell(graph, triple):\n",
    "    \"\"\"\n",
    "    triple = { \"subject\": \"...\", \"relation\": \"...\", \"object\": \"...\" }\n",
    "    \"\"\"\n",
    "    subj = triple[\"subject\"]\n",
    "    rel  = triple[\"relation\"]\n",
    "    obj  = triple[\"object\"]\n",
    "\n",
    "    result = find_similar_triples(graph, subj, rel, obj)\n",
    "\n",
    "    return {\n",
    "        \"input_triple\": triple,\n",
    "        \"exists_exact\": result[\"exact\"],\n",
    "        \"matched_subjects\": result[\"matched_subjects\"],\n",
    "        \"matched_objects\": result[\"matched_objects\"],\n",
    "        \"candidate_predicates\": result[\"candidate_predicates\"],\n",
    "        \"similar_triples\": result[\"similar_triples\"]\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# CHECK IF NAME / ENTITY EXISTS IN NELL\n",
    "# -----------------------------\n",
    "def entity_exists_exact(graph, name):\n",
    "    \"\"\"\n",
    "    Check if an entity URI matching the cleaned name exists in the graph.\n",
    "    \"\"\"\n",
    "    uri = text_to_uri(name)\n",
    "    return (uri, None, None) in graph or (None, None, uri) in graph\n",
    "\n",
    "\n",
    "def entity_exists_fuzzy(graph, name, threshold=70):\n",
    "    \"\"\"\n",
    "    Find entities with labels similar to 'name'.\n",
    "    \"\"\"\n",
    "    return find_by_label(graph, name, threshold=threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "786f6b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rodmb\\anaconda3\\envs\\rebel\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\rodmb\\anaconda3\\envs\\rebel\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\rodmb\\.cache\\huggingface\\hub\\models--sentence-transformers--all-MiniLM-L6-v2. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-25 15:52:34,198 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "\n",
      "===== RAW REBEL OUTPUT =====\n",
      " Randy Wolf  San Diego Padres  member of sports team  Kevin Kouzmanoff  San Diego Padres  member of sports team\n",
      "============================\n",
      "\n",
      "\n",
      "==== ENTITIES ====\n",
      "[{'text': 'San Diego Padres', 'type': 'ORG'}, {'text': 'Randy Wolf', 'type': 'PER'}, {'text': 'Kevin Kouzmanoff', 'type': 'PER'}, {'text': 'Padres', 'type': 'ORG'}, {'text': 'Randy Wolf', 'type': 'PER'}, {'text': 'San Diego Padres', 'type': 'ORG'}, {'text': 'National League', 'type': 'MISC'}, {'text': 'Padres', 'type': 'ORG'}, {'text': 'Kevin Kouzmanoff', 'type': 'PER'}, {'text': 'Padres', 'type': 'ORG'}, {'text': 'Major League Baseball', 'type': 'ORG'}, {'text': 'Padres', 'type': 'ORG'}, {'text': 'Wolf', 'type': 'PER'}, {'text': 'Kouzmanoff', 'type': 'PER'}, {'text': 'San Diegos', 'type': 'ORG'}]\n",
      "\n",
      "==== RELATIONS ====\n",
      "[{'subject': 'Randy Wolf', 'relation': 'member of sports team', 'object': 'San Diego Padres', 'subject_id': None, 'object_id': None}, {'subject': 'Kevin Kouzmanoff', 'relation': 'member of sports team', 'object': 'San Diego Padres', 'subject_id': None, 'object_id': None}]\n",
      "\n",
      "==== CHECKING REBEL RELATIONS AGAINST NELL =====\n",
      "\n",
      "\n",
      "REBEL TRIPLE: {'subject': 'Randy Wolf', 'relation': 'member of sports team', 'object': 'San Diego Padres', 'subject_id': None, 'object_id': None}\n",
      "\n",
      "-- SUBJECT CHECK --\n",
      "~ POSSIBLE subject matches:\n",
      "    concept_athlete_randy_wolf (score 100.0)\n",
      "\n",
      "-- OBJECT CHECK --\n",
      "~ POSSIBLE object matches:\n",
      "    concept_sportsteam_san_diego_padres (score 100.0)\n",
      "\n",
      "-- TRIPLE CHECK --\n",
      "✗ Triple NOT found in NELL\n",
      "No similar triples.\n",
      "---------------------\n",
      "  athleteplayssportsteamposition   (score=0.5966)\n",
      "  athleteplayssportsteamposition inv   (score=0.5541)\n",
      "  athleteplaysforteam   (score=0.5476)\n",
      "  athleteplayssport   (score=0.5253)\n",
      "  athleteflyouttosportsteamposition   (score=0.5112)\n",
      "\n",
      "-----------------------------------\n",
      "\n",
      "\n",
      "REBEL TRIPLE: {'subject': 'Kevin Kouzmanoff', 'relation': 'member of sports team', 'object': 'San Diego Padres', 'subject_id': None, 'object_id': None}\n",
      "\n",
      "-- SUBJECT CHECK --\n",
      "~ POSSIBLE subject matches:\n",
      "    concept_athlete_kevin_kouzmanoff (score 100.0)\n",
      "\n",
      "-- OBJECT CHECK --\n",
      "~ POSSIBLE object matches:\n",
      "    concept_sportsteam_san_diego_padres (score 100.0)\n",
      "\n",
      "-- TRIPLE CHECK --\n",
      "✗ Triple NOT found in NELL\n",
      "No similar triples.\n",
      "---------------------\n",
      "  athleteplayssportsteamposition   (score=0.5966)\n",
      "  athleteplayssportsteamposition inv   (score=0.5541)\n",
      "  athleteplaysforteam   (score=0.5476)\n",
      "  athleteplayssport   (score=0.5253)\n",
      "  athleteflyouttosportsteamposition   (score=0.5112)\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "def embedding_relation_similarity(rebel_rel, graph):\n",
    "    \"\"\"\n",
    "    Compare a REBEL relation to all KG relations using embedding cosine similarity.\n",
    "    No normalization. Pure semantic similarity.\n",
    "    \"\"\"\n",
    "    rebel_emb = embedder.encode(rebel_rel, convert_to_tensor=True)\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for r in set(graph.predicates()):\n",
    "        kg_label = str(r).split(\"/\")[-1].replace(\"_\", \" \").lower()\n",
    "        kg_emb = embedder.encode(kg_label, convert_to_tensor=True)\n",
    "\n",
    "        cos = util.cos_sim(rebel_emb, kg_emb).item()\n",
    "        results.append({\n",
    "            \"kg_relation\": kg_label,\n",
    "            \"embedding_score\": cos\n",
    "        })\n",
    "\n",
    "    # order from most similar to least\n",
    "    results.sort(key=lambda x: x[\"embedding_score\"], reverse=True)\n",
    "    return results\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load Models\n",
    "# -----------------------------------------------------------------------------\n",
    "ner_tagger = SequenceTagger.load(\"ner-large\")\n",
    "tokenizer_rebel = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model_rebel = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Cleaning\n",
    "# -----------------------------------------------------------------------------\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9\\s,.!?-]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Flair NER\n",
    "# -----------------------------------------------------------------------------\n",
    "def extract_entities(text):\n",
    "    sentence = Sentence(text)\n",
    "    ner_tagger.predict(sentence)\n",
    "    return [\n",
    "        {\"text\": ent.text, \"type\": ent.get_label('ner').value}\n",
    "        for ent in sentence.get_spans(\"ner\")\n",
    "    ]\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# RELATION NORMALIZATION & ADVANCED SIMILARITY\n",
    "# -----------------------------------------------------------------------------\n",
    "\n",
    "def normalize_nell_relation(rel_uri):\n",
    "    \"\"\"Convert NELL predicate URI into human-readable form.\"\"\"\n",
    "    frag = str(rel_uri).split(\"/\")[-1]              # athleteplayssport\n",
    "    frag = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", frag) # athlete plays sport\n",
    "    frag = frag.replace(\"_\", \" \")                   # athlete plays sport\n",
    "    return frag.lower().strip()\n",
    "\n",
    "\n",
    "def relation_token_similarity(rel1, rel2):\n",
    "    \"\"\"Compute token-overlap similarity between relations.\"\"\"\n",
    "    r1 = set(rel1.lower().split())\n",
    "    r2 = set(rel2.lower().split())\n",
    "    if not r1 or not r2:\n",
    "        return 0\n",
    "    overlap = len(r1 & r2)\n",
    "    return overlap / max(len(r1), len(r2))\n",
    "\n",
    "\n",
    "def relation_similarity(rebel_rel, nell_rel_uri):\n",
    "    \"\"\"Hybrid similarity: fuzzy + token-based.\"\"\"\n",
    "    rebel_norm = rebel_rel.lower().strip()\n",
    "    nell_norm = normalize_nell_relation(nell_rel_uri)\n",
    "\n",
    "    fuzzy_score = fuzz.ratio(rebel_norm, nell_norm) / 100.0\n",
    "    token_score = relation_token_similarity(rebel_norm, nell_norm)\n",
    "\n",
    "    # Weighted combination (token overlap is more important)\n",
    "    return 0.6 * token_score + 0.4 * fuzzy_score\n",
    "\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Parser for REBEL output (triples in one line)\n",
    "# -----------------------------------------------------------------------------\n",
    "def parse_rebel_output(text):\n",
    "    chunks = re.split(r\"\\s{2,}\", text.strip())\n",
    "\n",
    "    triples = []\n",
    "    i = 0\n",
    "    while i + 2 < len(chunks):\n",
    "        subj = chunks[i].strip()\n",
    "        obj  = chunks[i+1].strip()\n",
    "        rel  = chunks[i+2].strip()\n",
    "\n",
    "        triples.append({\n",
    "            \"subject\": subj,\n",
    "            \"relation\": rel,\n",
    "            \"object\": obj,\n",
    "            \"subject_id\": None,\n",
    "            \"object_id\": None\n",
    "        })\n",
    "        i += 3\n",
    "\n",
    "    return triples\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# REBEL wrapper\n",
    "# -----------------------------------------------------------------------------\n",
    "def extract_rebel_relations(text):\n",
    "    inputs = tokenizer_rebel(text, return_tensors=\"pt\", truncation=True)\n",
    "    outputs = model_rebel.generate(\n",
    "        **inputs,\n",
    "        max_length=256,\n",
    "        num_beams=3,\n",
    "        length_penalty=1.0\n",
    "    )\n",
    "\n",
    "    decoded = tokenizer_rebel.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"\\n===== RAW REBEL OUTPUT =====\")\n",
    "    print(decoded)\n",
    "    print(\"============================\\n\")\n",
    "\n",
    "    return parse_rebel_output(decoded)\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Combined pipeline\n",
    "# -----------------------------------------------------------------------------\n",
    "def getnlp(text):\n",
    "    cleaned = clean_text(text)\n",
    "\n",
    "    return {\n",
    "        \"clean_text\": cleaned.lower(),\n",
    "        \"entities\": extract_entities(cleaned),\n",
    "        \"relations\": extract_rebel_relations(cleaned)\n",
    "    }\n",
    "    \n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Example\n",
    "# -----------------------------------------------------------------------------\n",
    "article = \"\"\"The San Diego Padres have seen many players cycle through their roster, but certain names still stand out when looking back at specific phases of the franchise. Among those are Randy Wolf and Kevin Kouzmanoff, two players who, in different roles, contributed significantly while playing for the Padres.\n",
    "\n",
    "Left-handed pitcher Randy Wolf played for the San Diego Padres as part of their starting rotation, bringing veteran presence and stability to the mound. His ability to eat innings and compete against tough National League lineups helped anchor the Padres’ pitching staff during his time with the team.\n",
    "\n",
    "On the offensive side, Kevin Kouzmanoff also played for the Padres, providing power and production from the infield. As a third baseman, he delivered key hits and contributed both at the plate and in the field, becoming an important piece of the team’s everyday lineup.\n",
    "\n",
    "Both players operated within the broader context of Major League Baseball, representing the Padres in the sport of baseball at the highest professional level. Together, Wolf and Kouzmanoff illustrate how San Diego’s success has often depended on a combination of reliable pitching and solid infield offense—two pillars that have shaped many of the team’s competitive seasons.\"\"\"\n",
    "\n",
    "result = getnlp(article)\n",
    "\n",
    "print(\"\\n==== ENTITIES ====\")\n",
    "print(result[\"entities\"])\n",
    "\n",
    "print(\"\\n==== RELATIONS ====\")\n",
    "print(result[\"relations\"])\n",
    "\n",
    "print(\"\\n==== CHECKING REBEL RELATIONS AGAINST NELL =====\\n\")\n",
    "for tr in result[\"relations\"]:\n",
    "    print(f\"\\nREBEL TRIPLE: {tr}\")\n",
    "\n",
    "    subj = tr[\"subject\"]\n",
    "    rel  = tr[\"relation\"]\n",
    "    obj  = tr[\"object\"]\n",
    "\n",
    "    # ======================================\n",
    "    # 1. CHECK SUBJECT EXISTENCE\n",
    "    # ======================================\n",
    "    print(\"\\n-- SUBJECT CHECK --\")\n",
    "    if entity_exists_exact(g, subj):\n",
    "        print(f\"✓ EXACT subject match in NELL: {subj}\")\n",
    "    else:\n",
    "        fuzzy_s = entity_exists_fuzzy(g, subj)\n",
    "        if fuzzy_s:\n",
    "            print(f\"~ POSSIBLE subject matches:\")\n",
    "            for node, score in fuzzy_s[:5]:\n",
    "                print(f\"    {node} (score {score})\")\n",
    "        else:\n",
    "            print(f\"✗ No subject match for: {subj}\")\n",
    "\n",
    "    # ======================================\n",
    "    # 2. CHECK OBJECT EXISTENCE\n",
    "    # ======================================\n",
    "    print(\"\\n-- OBJECT CHECK --\")\n",
    "    if entity_exists_exact(g, obj):\n",
    "        print(f\"✓ EXACT object match in NELL: {obj}\")\n",
    "    else:\n",
    "        fuzzy_o = entity_exists_fuzzy(g, obj)\n",
    "        if fuzzy_o:\n",
    "            print(f\"~ POSSIBLE object matches:\")\n",
    "            for node, score in fuzzy_o[:5]:\n",
    "                print(f\"    {node} (score {score})\")\n",
    "        else:\n",
    "            print(f\"✗ No object match for: {obj}\")\n",
    "\n",
    "    # ======================================\n",
    "    # 3. CHECK TRIPLE EXISTENCE\n",
    "    # ======================================\n",
    "    print(\"\\n-- TRIPLE CHECK --\")\n",
    "    check = check_rebel_triple_against_nell(g, tr)\n",
    "\n",
    "    if check[\"similar_triples\"]:\n",
    "        print(\"~ Similar triples found:\")\n",
    "        for st in check[\"similar_triples\"][:5]:\n",
    "            print(f\"    {st['s']}  --{st['p']}-->  {st['o']} (scores={st['scores']})\")\n",
    "    else:\n",
    "        print(\"✗ Triple NOT found in NELL\")\n",
    "\n",
    "        if check[\"similar_triples\"]:\n",
    "            print(\"~ Similar triples found:\")\n",
    "            for st in check[\"similar_triples\"][:5]:\n",
    "                print(f\"    {st['s']}  --{st['r']}-->  {st['o']} (scores={st['scores']})\")\n",
    "        else:\n",
    "            print(\"No similar triples.\")\n",
    "        print(\"---------------------\")\n",
    "        embed_scores = embedding_relation_similarity(rel, g)\n",
    "\n",
    "        for s in embed_scores[:5]:\n",
    "            print(f\"  {s['kg_relation']}   (score={s['embedding_score']:.4f})\")\n",
    "\n",
    "    print(\"\\n-----------------------------------\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbfbdef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rebel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
