{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e111e0f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 308426 triples from kb_env_rl.txt\n"
     ]
    }
   ],
   "source": [
    "# ===========================\n",
    "# SECTION 1 — KG Initialization\n",
    "# ===========================\n",
    "\n",
    "from rdflib import Graph, Namespace, URIRef, RDF, RDFS, OWL, Literal\n",
    "from rapidfuzz import fuzz\n",
    "import re\n",
    "\n",
    "# -----------------------------\n",
    "# NAMESPACE\n",
    "# -----------------------------\n",
    "NELL = Namespace(\"http://nell-995.org/\")\n",
    "\n",
    "# -----------------------------\n",
    "# LOAD YOUR GRAPH (exactly as you had it)\n",
    "# -----------------------------\n",
    "g = Graph()\n",
    "g.bind(\"nell\", NELL)\n",
    "g.bind(\"owl\", OWL)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "SPORT_RELATIONS = {\n",
    "    \"athleteplayssport\",\n",
    "    \"athleteplayssport_inv\",\n",
    "    \"athleteplaysforteam\",\n",
    "    \"athleteplaysforteam_inv\",\n",
    "    \"athleteplayssportsteamposition\",\n",
    "    \"athleteplayssportsteamposition_inv\",\n",
    "    \"athleteflyouttosportsteamposition\",\n",
    "    \"athleteflyouttosportsteamposition_inv\",\n",
    "}\n",
    "# Generic entity class\n",
    "g.add((NELL.Entity, RDF.type, OWL.Class))\n",
    "\n",
    "def clean_uri(text):\n",
    "    return text.replace(\"concept:\", \"\").replace(\":\", \"_\").replace(\"/\", \"_\")\n",
    "def is_sport_relation(rel):\n",
    "    rel = rel.lower()\n",
    "    return rel in SPORT_RELATIONS\n",
    "# Load your KB file\n",
    "path = \"kb_env_rl.txt\"\n",
    "i = 0\n",
    "with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        parts = line.strip().split()\n",
    "        if len(parts) == 3:\n",
    "            subject, obj, relation = parts\n",
    "            s = URIRef(f\"{NELL}{clean_uri(subject)}\")\n",
    "            p = URIRef(f\"{NELL}{clean_uri(relation)}\")\n",
    "            o = URIRef(f\"{NELL}{clean_uri(obj)}\")\n",
    "            if not is_sport_relation(r):\n",
    "                continue\n",
    "            g.add((s, p, o))\n",
    "            g.add((p, RDF.type, OWL.ObjectProperty))\n",
    "            g.add((s, RDF.type, NELL.Entity))\n",
    "            g.add((o, RDF.type, NELL.Entity))\n",
    "            i += 1\n",
    "\n",
    "print(f\"Loaded {i} triples from kb_env_rl.txt\")\n",
    "\n",
    "# -----------------------------\n",
    "# HELPER FUNCTIONS\n",
    "# -----------------------------\n",
    "def clean_uri_fragment(text):\n",
    "    frag = text.replace(\"concept:\", \"\").replace(\":\", \"_\").replace(\"/\", \"_\").strip()\n",
    "    frag = re.sub(r\"\\s+\", \"_\", frag)\n",
    "    frag = re.sub(r\"[^\\w\\-_.]\", \"\", frag)\n",
    "    return frag\n",
    "\n",
    "def text_to_uri(text, ns=NELL):\n",
    "    return URIRef(f\"{ns}{clean_uri_fragment(text)}\")\n",
    "\n",
    "def get_labels(node, graph):\n",
    "    labels = set()\n",
    "\n",
    "    # rdfs:label if present\n",
    "    for L in graph.objects(node, RDFS.label):\n",
    "        if isinstance(L, Literal):\n",
    "            labels.add(str(L))\n",
    "\n",
    "    if isinstance(node, URIRef):\n",
    "        raw = str(node).split(\"/\")[-1]  # e.g., concept_city_vegas\n",
    "\n",
    "        # Original label\n",
    "        labels.add(raw.replace(\"_\", \" \"))\n",
    "\n",
    "        # Remove concept_ prefix\n",
    "        if raw.startswith(\"concept_\"):\n",
    "            labels.add(raw[len(\"concept_\"):].replace(\"_\", \" \"))\n",
    "\n",
    "        # Remove category prefix (e.g., city_, visualizablething_, etc.)\n",
    "        parts = raw.split(\"_\", 2)\n",
    "        if len(parts) >= 3:\n",
    "            labels.add(parts[2].replace(\"_\", \" \"))\n",
    "\n",
    "        # Add last fragment\n",
    "        labels.add(parts[-1])\n",
    "\n",
    "        # Add space-joined fragments after category prefix if more than 2\n",
    "        if len(parts) > 2:\n",
    "            labels.add(\" \".join(parts[1:]))\n",
    "            labels.add(\" \".join(parts[2:]))\n",
    "\n",
    "    return labels\n",
    "\n",
    "# -----------------------------\n",
    "# EXACT TRIPLE CHECK\n",
    "# -----------------------------\n",
    "def exists_exact_triple(graph, subj_text, rel_text, obj_text):\n",
    "    s = text_to_uri(subj_text)\n",
    "    p = text_to_uri(rel_text)\n",
    "    o = text_to_uri(obj_text)\n",
    "    return (s, p, o) in graph\n",
    "\n",
    "# -----------------------------\n",
    "# FUZZY LABEL MATCH\n",
    "# -----------------------------\n",
    "def find_by_label(graph, text, threshold=60):  # lower threshold from 85 → 60\n",
    "    text_norm = text.strip()\n",
    "    candidates = set(graph.subjects()) | set(graph.objects())\n",
    "\n",
    "    results = []\n",
    "    for node in candidates:\n",
    "        labels = get_labels(node, graph)\n",
    "        if not labels:\n",
    "            continue\n",
    "        best = max(fuzz.ratio(text_norm.lower(), lab.lower()) for lab in labels)\n",
    "        if best >= threshold:\n",
    "            results.append((node, best))\n",
    "\n",
    "    results.sort(key=lambda x: x[1], reverse=True)\n",
    "    return results\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# SIMILAR TRIPLE SEARCH\n",
    "# -----------------------------\n",
    "def find_similar_triples(graph, subj, rel, obj, label_threshold=85, rel_threshold=50):\n",
    "    matches = {\n",
    "        \"exact\": exists_exact_triple(graph, subj, rel, obj),\n",
    "        \"matched_subjects\": [],\n",
    "        \"matched_objects\": [],\n",
    "        \"candidate_predicates\": [],\n",
    "        \"similar_triples\": []\n",
    "    }\n",
    "\n",
    "    if matches[\"exact\"]:\n",
    "        return matches\n",
    "\n",
    "    # subject & object fuzzy matches\n",
    "    matches[\"matched_subjects\"] = find_by_label(graph, subj, threshold=label_threshold)\n",
    "    matches[\"matched_objects\"] = find_by_label(graph, obj, threshold=label_threshold)\n",
    "\n",
    "    # predicate fuzzy match\n",
    "    rel_norm = rel.replace(\"_\", \" \").strip()\n",
    "    for p in set(graph.predicates()):\n",
    "        frag = str(p).split(\"/\")[-1].replace(\"_\", \" \")\n",
    "        score = fuzz.ratio(rel_norm, frag)\n",
    "        if score >= rel_threshold:\n",
    "            matches[\"candidate_predicates\"].append((p, score))\n",
    "\n",
    "    # possible similar triples\n",
    "    for s_node, s_score in matches[\"matched_subjects\"]:\n",
    "        for o_node, o_score in matches[\"matched_objects\"]:\n",
    "            for p in graph.predicates(subject=s_node, object=o_node):\n",
    "                frag = str(p).split(\"/\")[-1].replace(\"_\", \" \")\n",
    "                rel_score = fuzz.ratio(rel, frag)\n",
    "\n",
    "                matches[\"similar_triples\"].append({\n",
    "                    \"s\": s_node,\n",
    "                    \"p\": p,\n",
    "                    \"o\": o_node,\n",
    "                    \"scores\": {\n",
    "                        \"subject\": s_score,\n",
    "                        \"predicate\": rel_score,\n",
    "                        \"object\": o_score\n",
    "                    }\n",
    "                })\n",
    "\n",
    "    # sort by relevance\n",
    "    matches[\"similar_triples\"].sort(\n",
    "        key=lambda t: sum(t[\"scores\"].values()), \n",
    "        reverse=True\n",
    "    )\n",
    "\n",
    "    return matches\n",
    "\n",
    "# -----------------------------\n",
    "# FINAL FUNCTION TO CALL FROM SECTION 2\n",
    "# -----------------------------\n",
    "def check_rebel_triple_against_nell(graph, triple):\n",
    "    \"\"\"\n",
    "    triple = { \"subject\": \"...\", \"relation\": \"...\", \"object\": \"...\" }\n",
    "    \"\"\"\n",
    "    subj = triple[\"subject\"]\n",
    "    rel  = triple[\"relation\"]\n",
    "    obj  = triple[\"object\"]\n",
    "\n",
    "    result = find_similar_triples(graph, subj, rel, obj)\n",
    "\n",
    "    return {\n",
    "        \"input_triple\": triple,\n",
    "        \"exists_exact\": result[\"exact\"],\n",
    "        \"matched_subjects\": result[\"matched_subjects\"],\n",
    "        \"matched_objects\": result[\"matched_objects\"],\n",
    "        \"candidate_predicates\": result[\"candidate_predicates\"],\n",
    "        \"similar_triples\": result[\"similar_triples\"]\n",
    "    }\n",
    "\n",
    "# -----------------------------\n",
    "# CHECK IF NAME / ENTITY EXISTS IN NELL\n",
    "# -----------------------------\n",
    "def entity_exists_exact(graph, name):\n",
    "    \"\"\"\n",
    "    Check if an entity URI matching the cleaned name exists in the graph.\n",
    "    \"\"\"\n",
    "    uri = text_to_uri(name)\n",
    "    return (uri, None, None) in graph or (None, None, uri) in graph\n",
    "\n",
    "\n",
    "def entity_exists_fuzzy(graph, name, threshold=85):\n",
    "    \"\"\"\n",
    "    Find entities with labels similar to 'name'.\n",
    "    \"\"\"\n",
    "    return find_by_label(graph, name, threshold=threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "786f6b8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-11-15 15:24:14,718 SequenceTagger predicts: Dictionary with 20 tags: <unk>, O, S-ORG, S-MISC, B-PER, E-PER, S-LOC, B-ORG, E-ORG, I-PER, S-PER, B-MISC, I-MISC, E-MISC, I-ORG, B-LOC, E-LOC, I-LOC, <START>, <STOP>\n",
      "\n",
      "===== RAW REBEL OUTPUT =====\n",
      " Perspective  Washington D.C.  located in the administrative territorial entity\n",
      "============================\n",
      "\n",
      "\n",
      "==== ENTITIES ====\n",
      "[{'text': 'Molly Moore', 'type': 'PER'}, {'text': 'Washington D.C.', 'type': 'LOC'}, {'text': 'Perspective', 'type': 'ORG'}, {'text': 'UNC Asheville', 'type': 'ORG'}, {'text': 'Blood', 'type': 'MISC'}, {'text': 'U.S. Food and Drug Administration', 'type': 'ORG'}, {'text': 'Orlovsky', 'type': 'PER'}, {'text': 'Fontainebleau', 'type': 'LOC'}, {'text': 'Las Vegas', 'type': 'LOC'}, {'text': 'Orzola island', 'type': 'LOC'}, {'text': 'align', 'type': 'ORG'}, {'text': 'Cristiano Ronaldo', 'type': 'PER'}, {'text': 'Riyadh', 'type': 'LOC'}, {'text': 'Washington D.C.', 'type': 'LOC'}, {'text': 'Molly Moore', 'type': 'PER'}, {'text': 'UNC Asheville', 'type': 'ORG'}, {'text': 'Blood', 'type': 'MISC'}, {'text': 'FDA', 'type': 'ORG'}, {'text': 'Orzola island', 'type': 'LOC'}, {'text': 'Las Vegas', 'type': 'LOC'}, {'text': 'Orlovsky', 'type': 'PER'}, {'text': 'UNC Ashevillenone', 'type': 'ORG'}, {'text': 'NELL KB', 'type': 'ORG'}]\n",
      "\n",
      "==== RELATIONS ====\n",
      "[{'subject': 'Perspective', 'relation': 'located in the administrative territorial entity', 'object': 'Washington D.C.', 'subject_id': None, 'object_id': None}]\n",
      "\n",
      "==== CHECKING REBEL RELATIONS AGAINST NELL =====\n",
      "\n",
      "\n",
      "REBEL TRIPLE: {'subject': 'Perspective', 'relation': 'located in the administrative territorial entity', 'object': 'Washington D.C.', 'subject_id': None, 'object_id': None}\n",
      "\n",
      "-- SUBJECT CHECK --\n",
      "~ POSSIBLE subject matches:\n",
      "    http://nell-995.org/concept_politicsblog_perspective (score 100.0)\n",
      "    http://nell-995.org/concept_physicalcharacteristic_perspective (score 100.0)\n",
      "\n",
      "-- OBJECT CHECK --\n",
      "~ POSSIBLE object matches:\n",
      "    http://nell-995.org/concept_televisionstation_washington_dc (score 92.85714285714286)\n",
      "    http://nell-995.org/concept_city_washington_dc (score 92.85714285714286)\n",
      "    http://nell-995.org/concept_city_washington_d_c (score 89.65517241379311)\n",
      "    http://nell-995.org/concept_televisionstation_washingtondc (score 88.88888888888889)\n",
      "    http://nell-995.org/concept_city_washington_d_ (score 85.71428571428572)\n",
      "\n",
      "-- TRIPLE CHECK --\n",
      "✗ Triple NOT found in NELL\n",
      "No similar triples.\n",
      "\n",
      "-----------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Load Models\n",
    "# -----------------------------------------------------------------------------\n",
    "ner_tagger = SequenceTagger.load(\"ner-large\")\n",
    "tokenizer_rebel = AutoTokenizer.from_pretrained(\"Babelscape/rebel-large\")\n",
    "model_rebel = AutoModelForSeq2SeqLM.from_pretrained(\"Babelscape/rebel-large\")\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Cleaning\n",
    "# -----------------------------------------------------------------------------\n",
    "def clean_text(text):\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "    text = re.sub(r\"#\\w+\", \"\", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9\\s,.!?-]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Flair NER\n",
    "# -----------------------------------------------------------------------------\n",
    "def extract_entities(text):\n",
    "    sentence = Sentence(text)\n",
    "    ner_tagger.predict(sentence)\n",
    "    return [\n",
    "        {\"text\": ent.text, \"type\": ent.get_label('ner').value}\n",
    "        for ent in sentence.get_spans(\"ner\")\n",
    "    ]\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Parser for your REBEL output:\n",
    "# \"Cristiano Ronaldo  Al Nassr  member of sports team\"\n",
    "# -----------------------------------------------------------------------------\n",
    "def parse_rebel_output(text):\n",
    "    \"\"\"\n",
    "    Parses REBEL model output and returns all triples in a list.\n",
    "    Each triple is expected to be on a separate line.\n",
    "    \"\"\"\n",
    "    triples = []\n",
    "    lines = text.strip().split(\"\\n\")\n",
    "    \n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        # Split by 2+ spaces to handle multi-word entities\n",
    "        parts = re.split(r\"\\s{2,}\", line)\n",
    "        if len(parts) == 3:\n",
    "            triples.append({\n",
    "                \"subject\": parts[0].strip(),\n",
    "                \"relation\": parts[2].strip(),\n",
    "                \"object\": parts[1].strip(),\n",
    "                \"subject_id\": None,\n",
    "                \"object_id\": None\n",
    "            })\n",
    "    return triples\n",
    "\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# REBEL wrapper\n",
    "# -----------------------------------------------------------------------------\n",
    "def extract_rebel_relations(text):\n",
    "    inputs = tokenizer_rebel(text, return_tensors=\"pt\", truncation=True)\n",
    "    outputs = model_rebel.generate(\n",
    "        **inputs,\n",
    "        max_length=256,\n",
    "        num_beams=3,\n",
    "        length_penalty=1.0\n",
    "    )\n",
    "\n",
    "    decoded = tokenizer_rebel.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "    print(\"\\n===== RAW REBEL OUTPUT =====\")\n",
    "    print(decoded)\n",
    "    print(\"============================\\n\")\n",
    "\n",
    "    return parse_rebel_output(decoded)\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Combined pipeline\n",
    "# -----------------------------------------------------------------------------\n",
    "def getnlp(text):\n",
    "    cleaned = clean_text(text)\n",
    "\n",
    "    return {\n",
    "        \"clean_text\": cleaned.lower(),\n",
    "        \"entities\": extract_entities(cleaned),\n",
    "        \"relations\": extract_rebel_relations(cleaned)\n",
    "    }\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# Example\n",
    "# -----------------------------------------------------------------------------\n",
    "article = \"\"\"\n",
    "Molly Moore currently works for Washington D.C., while the political blog Perspective is often described as a proxy for a new book published recently. In the field of unusual biological studies, researchers have noted that the crustacean nit competes with UNC Asheville in a surprising ecological modeling system, and that physical action organs are considered a subpart of the Blood website in certain medical ontologies. Historical data shows that the U.S. Food and Drug Administration acted at the date 2004, and athlete Orlovsky is registered at the coordinates 49.11667, 18.43333. The Fontainebleau visualizable object is also known to be located within Las Vegas, while Orzola island is mapped to the coordinates 29.21667, -13.45.\n",
    "\n",
    "However, not all reported claims align with the knowledge base. Some sources falsely state that Cristiano Ronaldo works for Riyadh, or that Washington D.C. is located within Molly Moore. Others incorrectly claim that UNC Asheville is a subpart of the crustacean nit, or that the Blood website works for human organs. Even more extreme assertions say that the year 2004 controls the FDA, that Orzola island is a proxy for Las Vegas, or that athlete Orlovsky is a proxy for UNC Asheville—none of which are supported by the NELL KB.\n",
    "\"\"\"\n",
    "\n",
    "result = getnlp(article)\n",
    "\n",
    "print(\"\\n==== ENTITIES ====\")\n",
    "print(result[\"entities\"])\n",
    "\n",
    "print(\"\\n==== RELATIONS ====\")\n",
    "print(result[\"relations\"])\n",
    "\n",
    "print(\"\\n==== CHECKING REBEL RELATIONS AGAINST NELL =====\\n\")\n",
    "for tr in result[\"relations\"]:\n",
    "    print(f\"\\nREBEL TRIPLE: {tr}\")\n",
    "\n",
    "    subj = tr[\"subject\"]\n",
    "    rel  = tr[\"relation\"]\n",
    "    obj  = tr[\"object\"]\n",
    "\n",
    "    # ======================================\n",
    "    # 1. CHECK SUBJECT EXISTENCE\n",
    "    # ======================================\n",
    "    print(\"\\n-- SUBJECT CHECK --\")\n",
    "    if entity_exists_exact(g, subj):\n",
    "        print(f\"✓ EXACT subject match in NELL: {subj}\")\n",
    "    else:\n",
    "        fuzzy_s = entity_exists_fuzzy(g, subj)\n",
    "        if fuzzy_s:\n",
    "            print(f\"~ POSSIBLE subject matches:\")\n",
    "            for node, score in fuzzy_s[:5]:\n",
    "                print(f\"    {node} (score {score})\")\n",
    "        else:\n",
    "            print(f\"✗ No subject match for: {subj}\")\n",
    "\n",
    "    # ======================================\n",
    "    # 2. CHECK OBJECT EXISTENCE\n",
    "    # ======================================\n",
    "    print(\"\\n-- OBJECT CHECK --\")\n",
    "    if entity_exists_exact(g, obj):\n",
    "        print(f\"✓ EXACT object match in NELL: {obj}\")\n",
    "    else:\n",
    "        fuzzy_o = entity_exists_fuzzy(g, obj)\n",
    "        if fuzzy_o:\n",
    "            print(f\"~ POSSIBLE object matches:\")\n",
    "            for node, score in fuzzy_o[:5]:\n",
    "                print(f\"    {node} (score {score})\")\n",
    "        else:\n",
    "            print(f\"✗ No object match for: {obj}\")\n",
    "\n",
    "    # ======================================\n",
    "    # 3. CHECK TRIPLE EXISTENCE\n",
    "    # ======================================\n",
    "    print(\"\\n-- TRIPLE CHECK --\")\n",
    "    check = check_rebel_triple_against_nell(g, tr)\n",
    "\n",
    "    if check[\"exists_exact\"]:\n",
    "        print(\"✓ EXACT triple exists in NELL\")\n",
    "    else:\n",
    "        print(\"✗ Triple NOT found in NELL\")\n",
    "\n",
    "        if check[\"similar_triples\"]:\n",
    "            print(\"~ Similar triples found:\")\n",
    "            for st in check[\"similar_triples\"][:5]:\n",
    "                print(f\"    {st['s']}  --{st['p']}-->  {st['o']} (scores={st['scores']})\")\n",
    "        else:\n",
    "            print(\"No similar triples.\")\n",
    "\n",
    "    print(\"\\n-----------------------------------\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36da5dd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "space",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
